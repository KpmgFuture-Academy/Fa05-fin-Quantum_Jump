"""
MySQL ë°ì´í„°ë² ì´ìŠ¤ ì„œë¹„ìŠ¤ - ê°„ë‹¨í•œ ë²„ì „
ë°±ê·¸ë¼ìš´ë“œ íŒŒì´í”„ë¼ì¸ ê²°ê³¼ ì €ìž¥ + API ì¡°íšŒìš©
"""

import mysql.connector
from mysql.connector import Error
from typing import List, Dict, Optional
import json
from datetime import datetime
from config import DATABASE_CONFIG

class DatabaseService:
    """MySQL ê¸°ë°˜ ë°ì´í„°ë² ì´ìŠ¤ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.connection = None
        self._initialized = False
    
    def initialize(self):
        """MySQL ì—°ê²° ì´ˆê¸°í™”"""
        try:
            self.connection = mysql.connector.connect(**DATABASE_CONFIG)
            if self.connection.is_connected():
                self._initialized = True
                print(f"âœ… MySQL ì—°ê²° ì„±ê³µ (í¬íŠ¸: {DATABASE_CONFIG['port']})")
                self._create_tables()
        except Error as e:
            print(f"âŒ MySQL ì—°ê²° ì‹¤íŒ¨: {e}")
            self._initialized = False
    
    def is_initialized(self) -> bool:
        """ì—°ê²° ìƒíƒœ í™•ì¸"""
        try:
            return (self._initialized and 
                   self.connection and 
                   self.connection.is_connected())
        except:
            return False
    
    async def test_connection(self):
        """ì—°ê²° í…ŒìŠ¤íŠ¸"""
        if not self.is_initialized():
            raise Exception("ë°ì´í„°ë² ì´ìŠ¤ê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        cursor = self.connection.cursor()
        try:
            cursor.execute("SELECT 1")
            cursor.fetchone()
            return True
        finally:
            cursor.close()
    
    def _create_tables(self):
        """í•„ìš”í•œ í…Œì´ë¸” ìƒì„±"""
        cursor = self.connection.cursor()
        
        try:
            # ë‰´ìŠ¤ ì´ìŠˆ í…Œì´ë¸”
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS news_issues (
                id INT PRIMARY KEY AUTO_INCREMENT,
                issue_number INT,
                title VARCHAR(500) NOT NULL,
                content TEXT,
                category VARCHAR(100),
                extracted_at DATETIME,
                stock_relevance_score DECIMAL(4,1),
                ranking INT,
                rag_confidence DECIMAL(4,1),
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
            ) ENGINE=InnoDB CHARSET=utf8mb4
            """)
            
            # ê´€ë ¨ ì‚°ì—… í…Œì´ë¸”
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS related_industries (
                id INT PRIMARY KEY AUTO_INCREMENT,
                news_issue_id INT NOT NULL,
                industry_name VARCHAR(200),
                final_score DECIMAL(4,1),
                ai_reason TEXT,
                FOREIGN KEY (news_issue_id) REFERENCES news_issues(id) ON DELETE CASCADE
            ) ENGINE=InnoDB CHARSET=utf8mb4
            """)
            
            # ê´€ë ¨ ê³¼ê±° ì´ìŠˆ í…Œì´ë¸”
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS related_past_issues (
                id INT PRIMARY KEY AUTO_INCREMENT,
                news_issue_id INT NOT NULL,
                issue_name VARCHAR(200),
                final_score DECIMAL(4,1),
                period VARCHAR(100),
                ai_reason TEXT,
                FOREIGN KEY (news_issue_id) REFERENCES news_issues(id) ON DELETE CASCADE
            ) ENGINE=InnoDB CHARSET=utf8mb4
            """)
            
            # íŒŒì´í”„ë¼ì¸ ë¡œê·¸ í…Œì´ë¸”
            cursor.execute("""
            CREATE TABLE IF NOT EXISTS pipeline_logs (
                id INT PRIMARY KEY AUTO_INCREMENT,
                pipeline_id VARCHAR(50),
                started_at DATETIME,
                completed_at DATETIME,
                final_status VARCHAR(20),
                total_crawled INT,
                selected_count INT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            ) ENGINE=InnoDB CHARSET=utf8mb4
            """)
            
            self.connection.commit()
            print("âœ… MySQL í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
            
        except Error as e:
            print(f"âŒ í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {e}")
            raise
        finally:
            cursor.close()
    
    # ========================================================================
    # íŒŒì´í”„ë¼ì¸ ê²°ê³¼ ì €ìž¥
    # ========================================================================
    
    async def save_pipeline_result(self, result: Dict):
        """íŒŒì´í”„ë¼ì¸ ê²°ê³¼ë¥¼ MySQLì— ì €ìž¥"""
        if not self.is_initialized():
            raise Exception("ë°ì´í„°ë² ì´ìŠ¤ê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        cursor = self.connection.cursor()
        
        try:
            print("ðŸ’¾ MySQLì— íŒŒì´í”„ë¼ì¸ ê²°ê³¼ ì €ìž¥ ì¤‘...")
            
            # ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (ìµœì‹  ìƒíƒœ ìœ ì§€)
            cursor.execute("DELETE FROM related_past_issues")
            cursor.execute("DELETE FROM related_industries")
            cursor.execute("DELETE FROM news_issues")
            
            # API ë°ì´í„° ì¶”ì¶œ
            api_data = result.get("api_ready_data", {})
            selected_issues = api_data.get("data", {}).get("selected_issues", [])
            
            # ìƒˆ ë‰´ìŠ¤ ì´ìŠˆë“¤ ì €ìž¥
            for issue_data in selected_issues:
                # 1. ë‰´ìŠ¤ ì´ìŠˆ ì €ìž¥
                issue_id = self._save_news_issue(cursor, issue_data)
                
                # 2. ê´€ë ¨ ì‚°ì—… ì €ìž¥
                for industry in issue_data.get("ê´€ë ¨ì‚°ì—…", []):
                    self._save_related_industry(cursor, issue_id, industry)
                
                # 3. ê´€ë ¨ ê³¼ê±° ì´ìŠˆ ì €ìž¥
                for past_issue in issue_data.get("ê´€ë ¨ê³¼ê±°ì´ìŠˆ", []):
                    self._save_related_past_issue(cursor, issue_id, past_issue)
            
            # íŒŒì´í”„ë¼ì¸ ë¡œê·¸ ì €ìž¥
            self._save_pipeline_log(cursor, result, api_data)
            
            self.connection.commit()
            print(f"âœ… MySQL ì €ìž¥ ì™„ë£Œ: {len(selected_issues)}ê°œ ì´ìŠˆ")
            
        except Error as e:
            self.connection.rollback()
            print(f"âŒ MySQL ì €ìž¥ ì‹¤íŒ¨: {e}")
            raise
        finally:
            cursor.close()
    
    def _save_news_issue(self, cursor, issue_data: Dict) -> int:
        """ë‰´ìŠ¤ ì´ìŠˆ ì €ìž¥"""
        query = """
        INSERT INTO news_issues 
        (issue_number, title, content, category, extracted_at, 
         stock_relevance_score, ranking, rag_confidence)
        VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
        """
        
        # ë‚ ì§œ ì²˜ë¦¬
        extracted_at = issue_data.get("ì¶”ì¶œì‹œê°„")
        if isinstance(extracted_at, str):
            try:
                extracted_at = datetime.fromisoformat(extracted_at.replace('Z', '+00:00'))
            except:
                extracted_at = datetime.now()
        
        values = (
            issue_data.get("ì´ìŠˆë²ˆí˜¸", 0),
            issue_data.get("ì œëª©", "")[:500],  # ê¸¸ì´ ì œí•œ
            issue_data.get("ë‚´ìš©", ""),
            issue_data.get("ì¹´í…Œê³ ë¦¬", ""),
            extracted_at,
            float(issue_data.get("ì£¼ì‹ì‹œìž¥_ê´€ë ¨ì„±_ì ìˆ˜", 0)),
            issue_data.get("ìˆœìœ„", 0),
            float(issue_data.get("RAGë¶„ì„ì‹ ë¢°ë„", 0))
        )
        
        cursor.execute(query, values)
        return cursor.lastrowid
    
    def _save_related_industry(self, cursor, news_issue_id: int, industry: Dict):
        """ê´€ë ¨ ì‚°ì—… ì €ìž¥"""
        query = """
        INSERT INTO related_industries 
        (news_issue_id, industry_name, final_score, ai_reason)
        VALUES (%s, %s, %s, %s)
        """
        
        values = (
            news_issue_id,
            industry.get("name", "")[:200],
            float(industry.get("final_score", 0)),
            industry.get("ai_reason", "")
        )
        
        cursor.execute(query, values)
    
    def _save_related_past_issue(self, cursor, news_issue_id: int, past_issue: Dict):
        """ê´€ë ¨ ê³¼ê±° ì´ìŠˆ ì €ìž¥"""
        query = """
        INSERT INTO related_past_issues 
        (news_issue_id, issue_name, final_score, period, ai_reason)
        VALUES (%s, %s, %s, %s, %s)
        """
        
        values = (
            news_issue_id,
            past_issue.get("name", "")[:200],
            float(past_issue.get("final_score", 0)),
            past_issue.get("period", ""),
            past_issue.get("ai_reason", "")
        )
        
        cursor.execute(query, values)
    
    def _save_pipeline_log(self, cursor, result: Dict, api_data: Dict):
        """íŒŒì´í”„ë¼ì¸ ë¡œê·¸ ì €ìž¥"""
        query = """
        INSERT INTO pipeline_logs 
        (pipeline_id, started_at, completed_at, final_status, total_crawled, selected_count)
        VALUES (%s, %s, %s, %s, %s, %s)
        """
        
        def parse_datetime(date_str):
            if not date_str:
                return None
            try:
                return datetime.fromisoformat(date_str.replace('Z', '+00:00'))
            except:
                return None
        
        values = (
            result.get("pipeline_id", ""),
            parse_datetime(result.get("started_at")),
            parse_datetime(result.get("completed_at")),
            result.get("final_status", ""),
            api_data.get("data", {}).get("total_crawled", 0),
            api_data.get("data", {}).get("selected_count", 0)
        )
        
        cursor.execute(query, values)
    
    # ========================================================================
    # ë°ì´í„° ì¡°íšŒ (APIìš©)
    # ========================================================================
    
    async def get_latest_news_issues(self) -> List[Dict]:
        """ìµœì‹  ë‰´ìŠ¤ ì´ìŠˆë“¤ ì¡°íšŒ"""
        if not self.is_initialized():
            return []
        
        cursor = self.connection.cursor(dictionary=True)
        
        try:
            # ë‰´ìŠ¤ ì´ìŠˆ ì¡°íšŒ
            cursor.execute("""
            SELECT * FROM news_issues 
            ORDER BY ranking ASC
            """)
            news_issues = cursor.fetchall()
            
            # ê° ì´ìŠˆì— ê´€ë ¨ ì •ë³´ ì¶”ê°€
            for issue in news_issues:
                issue_id = issue['id']
                
                # ê´€ë ¨ ì‚°ì—… ì¡°íšŒ
                cursor.execute("""
                SELECT industry_name, final_score, ai_reason
                FROM related_industries 
                WHERE news_issue_id = %s 
                ORDER BY final_score DESC
                """, (issue_id,))
                issue['related_industries'] = cursor.fetchall()
                
                # ê´€ë ¨ ê³¼ê±° ì´ìŠˆ ì¡°íšŒ
                cursor.execute("""
                SELECT issue_name, final_score, period, ai_reason
                FROM related_past_issues 
                WHERE news_issue_id = %s 
                ORDER BY final_score DESC
                """, (issue_id,))
                issue['related_past_issues'] = cursor.fetchall()
                
                # ë‚ ì§œ í˜•ì‹ ë³€í™˜
                if issue.get('extracted_at'):
                    issue['extracted_at'] = issue['extracted_at'].isoformat()
                if issue.get('updated_at'):
                    issue['updated_at'] = issue['updated_at'].isoformat()
            
            return news_issues
            
        except Error as e:
            print(f"âŒ ë‰´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
        finally:
            cursor.close()
    
    async def get_issue_with_relations(self, issue_id: int) -> Optional[Dict]:
        """íŠ¹ì • ì´ìŠˆ ìƒì„¸ ì¡°íšŒ"""
        if not self.is_initialized():
            return None
        
        cursor = self.connection.cursor(dictionary=True)
        
        try:
            # ë‰´ìŠ¤ ì´ìŠˆ ê¸°ë³¸ ì •ë³´
            cursor.execute("SELECT * FROM news_issues WHERE id = %s", (issue_id,))
            issue = cursor.fetchone()
            
            if not issue:
                return None
            
            # ê´€ë ¨ ì‚°ì—…
            cursor.execute("""
            SELECT industry_name, final_score, ai_reason
            FROM related_industries WHERE news_issue_id = %s
            """, (issue_id,))
            issue['related_industries'] = cursor.fetchall()
            
            # ê´€ë ¨ ê³¼ê±° ì´ìŠˆ
            cursor.execute("""
            SELECT issue_name, final_score, period, ai_reason
            FROM related_past_issues WHERE news_issue_id = %s
            """, (issue_id,))
            issue['related_past_issues'] = cursor.fetchall()
            
            return issue
            
        except Error as e:
            print(f"âŒ ì´ìŠˆ ìƒì„¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
        finally:
            cursor.close()
    
    async def get_latest_pipeline_log(self) -> Optional[Dict]:
        """ìµœê·¼ íŒŒì´í”„ë¼ì¸ ë¡œê·¸ ì¡°íšŒ"""
        if not self.is_initialized():
            return None
        
        cursor = self.connection.cursor(dictionary=True)
        
        try:
            cursor.execute("""
            SELECT * FROM pipeline_logs 
            ORDER BY created_at DESC 
            LIMIT 1
            """)
            result = cursor.fetchone()
            
            if result:
                # ë‚ ì§œ í˜•ì‹ ë³€í™˜
                for date_field in ['started_at', 'completed_at', 'created_at']:
                    if result.get(date_field):
                        result[date_field] = result[date_field].isoformat()
            
            return result
            
        except Error as e:
            print(f"âŒ íŒŒì´í”„ë¼ì¸ ë¡œê·¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None
        finally:
            cursor.close()

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_database_service = None

def get_database_service() -> DatabaseService:
    global _database_service
    if _database_service is None:
        _database_service = DatabaseService()
    return _database_service