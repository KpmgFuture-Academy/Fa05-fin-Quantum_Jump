"""
RAG ë¶„ì„ ì„œë¹„ìŠ¤ - ìµœì¢… ê°œì„  ë²„ì „
- ê²€ì¦ ë ˆì´ì–´(Verification Layer) ì¶”ê°€
- ë‹¤ì°¨ì› ì‹ ë¢°ë„(ì¼ê´€ì„±+ìµœê³  ì—°ê´€ë„) ë„ì…
- í›„ë³´êµ° ìƒì„± ë¡œì§ ê°œì„  (ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ -> AI ë¶„ì„ -> ê²€ì¦)
- ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”
"""

import os
import json
import pandas as pd
from pathlib import Path
from typing import Dict, List, Optional
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from pinecone import Pinecone

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv(override=True)

class RAGService:
    """RAG ë¶„ì„ ì„œë¹„ìŠ¤ (ê²€ì¦ ë° ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™” ë²„ì „)"""
    
    def __init__(self):
        # í™˜ê²½ ì„¤ì •
        self.EMBEDDING_MODEL = os.getenv("OPENAI_EMBEDDING_MODEL", "text-embedding-3-small")
        self.INDEX_NAME = os.getenv("PINECONE_INDEX_NAME", "ordaproject")
        self.PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
        
        # LLM ì´ˆê¸°í™” (ë¶„ì„ìš©, ê²€ì¦ìš©)
        self.analyzer_llm = ChatOpenAI(model="gpt-4o", temperature=0)
        self.verifier_llm = ChatOpenAI(model="gpt-4o-mini", temperature=0) # ê²€ì¦ì€ ë” ë¹ ë¥´ê³  ì €ë ´í•œ ëª¨ë¸ ì‚¬ìš©
        self.embedding = OpenAIEmbeddings(model=self.EMBEDDING_MODEL)
        
        # Pinecone í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.pc = Pinecone(api_key=self.PINECONE_API_KEY)
        self.index = self.pc.Index(self.INDEX_NAME)
        
        # ë°ì´í„°ë² ì´ìŠ¤ ë¡œë”©
        self._load_databases()
        
        print("âœ… RAG ë¶„ì„ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ (ê²€ì¦ ë ˆì´ì–´ ë° ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”)")
    
    def _load_databases(self):
        """ì‚°ì—… DB ë° ê³¼ê±° ì´ìŠˆ DB ë¡œë”©"""
        try:
            # ì‚°ì—… DB ë¡œë”©
            self.industry_df = pd.read_csv("data/ì‚°ì—…DB.v.0.3.csv")
            self.industry_dict = dict(zip(self.industry_df["KRX ì—…ì¢…ëª…"], self.industry_df["ìƒì„¸ë‚´ìš©"]))
            print(f"âœ… ì‚°ì—… DB ë¡œë“œ: {len(self.industry_dict)}ê°œ ì—…ì¢…")
            
            # ê³¼ê±° ì´ìŠˆ DB ë¡œë”©
            self.past_df = pd.read_csv("data/Past_news.csv")
            self.issue_dict = dict(zip(
                self.past_df["Issue_name"], 
                self.past_df["Contents"] + "\n\nìƒì„¸: " + self.past_df["Contentes(Spec)"]
            ))
            print(f"âœ… ê³¼ê±° ì´ìŠˆ DB ë¡œë“œ: {len(self.issue_dict)}ê°œ ì´ìŠˆ")
            
        except Exception as e:
            print(f"âš ï¸ DB ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.industry_dict = {}
            self.issue_dict = {}

    def analyze_issues_with_rag(self, filtered_issues: List[Dict]) -> List[Dict]:
        """í•„í„°ë§ëœ ì´ìŠˆë“¤ì— ëŒ€í•´ RAG ë¶„ì„ ìˆ˜í–‰ (ì˜¤ë¥˜ ë°©ì§€ ê°•í™”)"""
        print(f"ğŸ” RAG ë¶„ì„ ì‹œì‘: {len(filtered_issues)}ê°œ ì´ìŠˆ")
        enriched_issues = []
        
        for i, issue in enumerate(filtered_issues, 1):
            print(f"ğŸ”„ ì´ìŠˆ {i}/{len(filtered_issues)} RAG ë¶„ì„ ì¤‘: {issue.get('ì œëª©', 'N/A')[:50]}...")
            
            try:
                # ê´€ë ¨ ì‚°ì—… ë¶„ì„
                related_industries = self._analyze_industry_for_issue(issue)
                
                # ê´€ë ¨ ê³¼ê±° ì´ìŠˆ ë¶„ì„
                related_past_issues = self._analyze_past_issues_for_issue(issue)
                
                # ì•ˆì „í•œ RAG ë‹¤ì°¨ì› ì‹ ë¢°ë„ ê³„ì‚°
                rag_confidence = self._calculate_rag_confidence(related_industries, related_past_issues)
                
                # ê¸°ë³¸ ì´ìŠˆì— RAG ê²°ê³¼ ì¶”ê°€
                enriched_issue = issue.copy()
                enriched_issue.update({
                    "ê´€ë ¨ì‚°ì—…": related_industries,
                    "ê´€ë ¨ê³¼ê±°ì´ìŠˆ": related_past_issues,
                    "RAGë¶„ì„ì‹ ë¢°ë„": rag_confidence
                })
                enriched_issues.append(enriched_issue)
                
                confidence_display = self._format_confidence_for_display(rag_confidence)
                print(f"  âœ… ì´ìŠˆ {i} RAG ì™„ë£Œ: ì‹ ë¢°ë„ {confidence_display}")
                
            except Exception as e:
                print(f"  âŒ ì´ìŠˆ {i} RAG ë¶„ì„ ì‹¤íŒ¨: {e}")
                # ì‹¤íŒ¨í•œ ê²½ìš°ì—ë„ ê¸°ë³¸ êµ¬ì¡° ìœ ì§€í•˜ë©° ë‹¤ìŒ ì´ìŠˆë¡œ ì§„í–‰
                enriched_issue = issue.copy()
                enriched_issue.update({
                    "ê´€ë ¨ì‚°ì—…": [],
                    "ê´€ë ¨ê³¼ê±°ì´ìŠˆ": [],
                    "RAGë¶„ì„ì‹ ë¢°ë„": {"consistency_score": 0.0, "peak_relevance_score": 0.0},
                    "error": str(e)
                })
                enriched_issues.append(enriched_issue)
        
        avg_confidence = self._calculate_average_confidence(enriched_issues)
        print(f"âœ… RAG ë¶„ì„ ì™„ë£Œ: ì „ì²´ í‰ê·  ì¼ê´€ì„± ì ìˆ˜ {avg_confidence}")
        
        return enriched_issues

    def _analyze_industry_for_issue(self, issue: Dict) -> List[Dict]:
        """íŠ¹ì • ì´ìŠˆì— ëŒ€í•œ ê´€ë ¨ ì‚°ì—… ë¶„ì„ (ê²€ì¦ ë ˆì´ì–´ í¬í•¨)"""
        query = f"{issue.get('ì œëª©', '')}\n{issue.get('ì›ë³¸ë‚´ìš©', issue.get('ë‚´ìš©', ''))}"
        
        # Step 1: ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ 1ì°¨ í›„ë³´êµ° ì¶”ì¶œ
        vector_candidates = self._vector_search(query, namespace="industry")
        
        # Step 2: AI Agentê°€ 1ì°¨ í›„ë³´êµ°ì„ ì¬í‰ê°€(Rerank)
        ai_candidates = self._ai_rerank_candidates(query, vector_candidates, "industry")
        
        # Step 3: ê²°ê³¼ í†µí•© ë° ì •ë ¬
        combined_candidates = self._combine_results(vector_candidates, ai_candidates, "industry")
        
        # Step 4: ê²€ì¦ ë ˆì´ì–´ (ìƒìœ„ 3ê°œ í›„ë³´ì— ëŒ€í•´ ìˆ˜í–‰)
        verified_candidates = self._apply_verification_layer(query, combined_candidates)
        
        # Step 5: ìµœì¢… ì •ë ¬ í›„ ë°˜í™˜
        return sorted(verified_candidates, key=lambda x: x["final_score"], reverse=True)

    def _analyze_past_issues_for_issue(self, issue: Dict) -> List[Dict]:
        """íŠ¹ì • ì´ìŠˆì— ëŒ€í•œ ê´€ë ¨ ê³¼ê±° ì´ìŠˆ ë¶„ì„ (ê²€ì¦ ë ˆì´ì–´ í¬í•¨)"""
        query = f"{issue.get('ì œëª©', '')}\n{issue.get('ì›ë³¸ë‚´ìš©', issue.get('ë‚´ìš©', ''))}"
        
        # Step 1: ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ 1ì°¨ í›„ë³´êµ° ì¶”ì¶œ
        vector_candidates = self._vector_search(query, namespace="past_issue")

        # Step 2: AI Agentê°€ 1ì°¨ í›„ë³´êµ°ì„ ì¬í‰ê°€(Rerank)
        ai_candidates = self._ai_rerank_candidates(query, vector_candidates, "past_issue")
        
        # Step 3: ê²°ê³¼ í†µí•© ë° ì •ë ¬
        combined_candidates = self._combine_results(vector_candidates, ai_candidates, "past_issue")
        
        # Step 4: ê²€ì¦ ë ˆì´ì–´ (ìƒìœ„ 3ê°œ í›„ë³´ì— ëŒ€í•´ ìˆ˜í–‰)
        verified_candidates = self._apply_verification_layer(query, combined_candidates)

        # Step 5: ìµœì¢… ì •ë ¬ í›„ ë°˜í™˜
        return sorted(verified_candidates, key=lambda x: x["final_score"], reverse=True)
    
    def _vector_search(self, query: str, namespace: str, top_k: int = 10) -> List[Dict]:
        """Pinecone ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰"""
        try:
            query_embedding = self.embedding.embed_query(query)
            search_results = self.index.query(
                vector=query_embedding, top_k=top_k, include_metadata=True, namespace=namespace
            )
            
            candidates = []
            for match in search_results.matches:
                meta = match.metadata or {}
                name = meta.get("name")
                if name and not any(c["name"] == name for c in candidates):
                    candidates.append({
                        "name": name,
                        "similarity": round(match.score * 100, 1),
                        "description": meta.get("description", ""),
                        "period": f"{meta.get('start_date', '')} ~ {meta.get('end_date', '')}" if namespace == 'past_issue' else None
                    })
            print(f"  ğŸ“Š {namespace} ë²¡í„° ê²€ìƒ‰: {len(candidates)}ê°œ í›„ë³´ ë°œê²¬")
            return candidates
        except Exception as e:
            print(f"âŒ {namespace} ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def _ai_rerank_candidates(self, news_content: str, vector_candidates: List[Dict], mode: str) -> List[Dict]:
        """AI Agentê°€ ë²¡í„° ê²€ìƒ‰ í›„ë³´êµ°ì„ ì¬í‰ê°€í•˜ì—¬ ìˆœìœ„, ì ìˆ˜, ì´ìœ  ë¶€ì—¬"""
        if not vector_candidates: return []
        
        task_description = {
            "industry": "ë‰´ìŠ¤ì™€ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ ìˆœì„œëŒ€ë¡œ ìˆœìœ„ë¥¼ ë§¤ê¸°ê³  ì ìˆ˜ì™€ ì´ìœ ë¥¼ ë¶€ì—¬",
            "past_issue": "í˜„ì¬ ë‰´ìŠ¤ì™€ ê°€ì¥ ìœ ì‚¬í•œ íŒ¨í„´ì„ ë³´ì´ëŠ” ìˆœì„œëŒ€ë¡œ ìˆœìœ„ë¥¼ ë§¤ê¸°ê³  ì ìˆ˜ì™€ ì´ìœ ë¥¼ ë¶€ì—¬"
        }.get(mode)
        
        field_name = "industry" if mode == "industry" else "issue"

        prompt = ChatPromptTemplate.from_messages([
            ("system", f"ë„ˆëŠ” ë‰´ìŠ¤ì™€ì˜ ê´€ë ¨ì„±ì„ íŒë‹¨í•˜ëŠ” ì „ë¬¸ ì• ë„ë¦¬ìŠ¤íŠ¸ë‹¤. ì£¼ì–´ì§„ ë‰´ìŠ¤ ë‚´ìš©ê³¼ í›„ë³´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬, {task_description}í•´ì•¼ í•œë‹¤. ì¶œë ¥ì€ JSON í˜•ì‹ì´ì–´ì•¼ í•œë‹¤."),
            ("human", """
[ë‰´ìŠ¤ ë‚´ìš©]
{news}

[í›„ë³´ ë¦¬ìŠ¤íŠ¸] 
{candidate_list}

ìœ„ ë‰´ìŠ¤ ë‚´ìš©ê³¼ ê´€ë ¨ì„±ì´ ë†’ì€ ìˆœì„œëŒ€ë¡œ í›„ë³´ë“¤ì˜ ìˆœìœ„ë¥¼ ë‹¤ì‹œ ì •ë ¬í•˜ê³ , ê° í›„ë³´ì— ëŒ€í•´ ê´€ë ¨ì„± ì ìˆ˜(1-10ì )ì™€ ê°„ë‹¨í•œ ì´ìœ ë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”.

ì¶œë ¥ í˜•ì‹ (JSON):
{{
  "candidates": [
    {{"{field}": "í›„ë³´ëª…", "score": ì ìˆ˜, "reason": "ê´€ë ¨ì„± ì´ìœ "}}, ...
  ]
}}""")
        ])
        
        parser = JsonOutputParser()
        chain = prompt | self.analyzer_llm | parser
        
        candidate_names = [c['name'] for c in vector_candidates]
        
        try:
            result = chain.invoke({
                "news": news_content, 
                "candidate_list": ", ".join(candidate_names),
                "field": field_name
            })
            candidates = result.get("candidates", [])
            print(f"  ğŸ¤– AI {mode} ì¬í‰ê°€: {len(candidates)}ê°œ í›„ë³´ ìƒì„±")
            return candidates
        except Exception as e:
            print(f"âŒ AI {mode} í›„ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []

    def _combine_results(self, vector_candidates: List[Dict], ai_candidates: List[Dict], mode: str) -> List[Dict]:
        """ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ì™€ AI ì¬í‰ê°€ ê²°ê³¼ë¥¼ ê²°í•©í•˜ì—¬ ìµœì¢… ì ìˆ˜ ê³„ì‚°"""
        all_candidates = {}
        field_name = "industry" if mode == "industry" else "issue"
        
        for candidate in vector_candidates:
            name = candidate["name"]
            all_candidates[name] = {
                "name": name,
                "vector_score": min(candidate["similarity"] / 10, 10),
                "ai_score": 0, "ai_reason": "",
                "description": candidate["description"],
                "period": candidate.get("period")
            }
        
        for candidate in ai_candidates:
            name = candidate.get(field_name)
            if name in all_candidates:
                all_candidates[name]["ai_score"] = candidate.get("score", 0)
                all_candidates[name]["ai_reason"] = candidate.get("reason", "")
        
        for candidate in all_candidates.values():
            vector_score = candidate.get("vector_score", 0)
            ai_score = candidate.get("ai_score", 0)
            candidate["final_score"] = round((vector_score * 0.3 + ai_score * 0.7), 1)
        
        return sorted(all_candidates.values(), key=lambda x: x.get("final_score", 0), reverse=True)

    def _apply_verification_layer(self, news_content: str, candidates: List[Dict], top_k: int = 3) -> List[Dict]:
        """ìƒìœ„ í›„ë³´êµ°ì— ëŒ€í•´ ê²€ì¦ ë ˆì´ì–´ ì ìš©"""
        verified_candidates = []
        for candidate in candidates[:top_k]:
            print(f"  ğŸ” ê²€ì¦ ì‹œì‘: {candidate['name']}")
            verification_result = self._verify_reasoning(
                news_content=news_content,
                item_name=candidate['name'],
                reason=candidate.get('ai_reason', '')
            )
            candidate['verification'] = verification_result
            if not verification_result.get('is_grounded'):
                candidate['final_score'] = round(candidate['final_score'] * 0.5, 1) # ê²€ì¦ ì‹¤íŒ¨ ì‹œ 50% í˜ë„í‹°
                print(f"    âŒ ê²€ì¦ ì‹¤íŒ¨: {candidate['name']}")
            else:
                print(f"    âœ… ê²€ì¦ ì„±ê³µ: {candidate['name']}")
            verified_candidates.append(candidate)
        
        return verified_candidates
        
    def _verify_reasoning(self, news_content: str, item_name: str, reason: str) -> dict:
        """AIê°€ ìƒì„±í•œ ë¶„ì„ ê·¼ê±°ê°€ ì›ë³¸ ë‰´ìŠ¤ì— ê¸°ë°˜í•˜ëŠ”ì§€ ê²€ì¦ (ì‹¤íŒ¨ ì´ìœ  í¬í•¨)"""
        if not reason:
            return {"is_grounded": False, "supporting_quote": "", "unverified_reason": "AIê°€ ë¶„ì„ ê·¼ê±°ë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŒ"}

        # ğŸ”¥ [ìˆ˜ì •] í”„ë¡¬í”„íŠ¸ì— 'unverified_reason' í•„ë“œì™€ ì‹¤íŒ¨ ì´ìœ  ì‘ì„± ìš”ì²­ ì¶”ê°€
        prompt = ChatPromptTemplate.from_template("""
system: ë„ˆëŠ” ë§¤ìš° ê¼¼ê¼¼í•œ íŒ©íŠ¸ì²´ì»¤(Fact-Checker)ë‹¤. 'ë¶„ì„ ê·¼ê±°'ê°€ 'ì›ë³¸ ë‰´ìŠ¤' ë‚´ìš©ì— ê¸°ë°˜í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ê²°ê³¼ëŠ” ë°˜ë“œì‹œ JSONìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•œë‹¤.
human:
[ì›ë³¸ ë‰´ìŠ¤]
{news}

[ë¶„ì„ ëŒ€ìƒ]: {item}
[ë¶„ì„ ê·¼ê±°]: {reason}

'ë¶„ì„ ê·¼ê±°'ê°€ 'ì›ë³¸ ë‰´ìŠ¤'ì— ê¸°ë°˜í•˜ë©´ `is_grounded`ë¥¼ `true`ë¡œ, ê·¼ê±° ë¬¸ì¥ì„ `supporting_quote`ì— ë„£ê³  `unverified_reason`ì€ ë¹ˆ ë¬¸ìì—´("")ë¡œ ì„¤ì •í•´.
ë§Œì•½ 'ì›ë³¸ ë‰´ìŠ¤'ì—ì„œ ê·¼ê±°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ê³¼ë„í•œ ì¶”ë¡ ì´ë¼ë©´ `is_grounded`ë¥¼ `false`ë¡œ, `supporting_quote`ëŠ” ë¹„ì›Œë‘ê³ , ì‹¤íŒ¨ ì´ìœ ë¥¼ `unverified_reason`ì— ê°„ê²°í•˜ê²Œ ì‘ì„±í•´ì¤˜. (ì˜ˆ: "ë‰´ìŠ¤ì— ì–¸ê¸‰ë˜ì§€ ì•Šì€ ë‚´ìš©", "ê³¼ë„í•œ ì¶”ë¡ ", "ë‚´ìš© ë¶ˆì¼ì¹˜")

JSON ì¶œë ¥ í˜•ì‹:
{{
    "is_grounded": boolean,
    "supporting_quote": "ì¸ìš©ë¬¸",
    "unverified_reason": "ì‹¤íŒ¨ ì´ìœ "
}}
""")
        parser = JsonOutputParser()
        chain = prompt | self.verifier_llm | parser

        try:
            return chain.invoke({ "news": news_content, "item": item_name, "reason": reason })
        except Exception as e:
            print(f"âš ï¸ ê²€ì¦ ë ˆì´ì–´ ì‹¤íŒ¨: {e}")
            # ğŸ”¥ [ìˆ˜ì •] ì˜ˆì™¸ ë°œìƒ ì‹œ ë°˜í™˜ê°’ì— unverified_reason ì¶”ê°€
            return {"is_grounded": False, "supporting_quote": "", "unverified_reason": "ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ"}

    def _calculate_rag_confidence(self, industries: List[Dict], past_issues: List[Dict]) -> dict:
        """RAG ë¶„ì„ ì‹ ë¢°ë„ë¥¼ ë‹¤ê°ì ìœ¼ë¡œ ê³„ì‚° (ì¼ê´€ì„± ì ìˆ˜ + ìµœê³  ì—°ê´€ë„ í‰ê· )"""
        if not industries and not past_issues:
            return {"consistency_score": 0.0, "peak_relevance_score": 0.0}
        
        # --- 1. ì¼ê´€ì„± ì ìˆ˜ (í‰ê·  ë°©ì‹) ---
        total_avg_score = 0
        count = 0
        if industries:
            # ìœ íš¨í•œ ì ìˆ˜ë§Œ í•„í„°ë§í•˜ì—¬ í‰ê·  ê³„ì‚°
            valid_scores = [ind.get("final_score", 0) for ind in industries if isinstance(ind.get("final_score"), (int, float))]
            if valid_scores:
                industry_avg = sum(valid_scores) / len(valid_scores)
                total_avg_score += industry_avg
                count += 1
        if past_issues:
            # ìœ íš¨í•œ ì ìˆ˜ë§Œ í•„í„°ë§í•˜ì—¬ í‰ê·  ê³„ì‚°
            valid_scores = [issue.get("final_score", 0) for issue in past_issues if isinstance(issue.get("final_score"), (int, float))]
            if valid_scores:
                past_avg = sum(valid_scores) / len(valid_scores)
                total_avg_score += past_avg
                count += 1
        consistency_score = round(total_avg_score / count if count > 0 else 0, 1)

        # --- ğŸ”¥ [ìˆ˜ì •] 2. ìµœê³  ì—°ê´€ë„ (ìµœê³ ì ë“¤ì˜ 'í‰ê· ' ë°©ì‹) ---
        peak_scores = []
        if industries:
            valid_scores = [ind.get("final_score", 0) for ind in industries if isinstance(ind.get("final_score"), (int, float))]
            if valid_scores:
                # 'ê´€ë ¨ ì‚°ì—…'ì˜ ìµœê³  ì ìˆ˜ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                peak_scores.append(max(valid_scores))
        
        if past_issues:
            valid_scores = [issue.get("final_score", 0) for issue in past_issues if isinstance(issue.get("final_score"), (int, float))]
            if valid_scores:
                # 'ê³¼ê±° ì´ìŠˆ'ì˜ ìµœê³  ì ìˆ˜ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                peak_scores.append(max(valid_scores))
        
        # ìˆ˜ì§‘ëœ ìµœê³  ì ìˆ˜ë“¤ì˜ í‰ê· ì„ ê³„ì‚°
        if peak_scores:
            peak_relevance_score = round(sum(peak_scores) / len(peak_scores), 1)
        else:
            peak_relevance_score = 0.0
        
        return { 
            "consistency_score": consistency_score, 
            "peak_relevance_score": peak_relevance_score 
        }
    
    def _calculate_average_confidence(self, enriched_issues: List[Dict]) -> float:
        """ì•ˆì „í•œ ì „ì²´ ì´ìŠˆë“¤ì˜ í‰ê·  RAG ì¼ê´€ì„± ì ìˆ˜ ê³„ì‚°"""
        if not enriched_issues: return 0.0
        try:
            confidences = []
            for issue in enriched_issues:
                rag_confidence = issue.get("RAGë¶„ì„ì‹ ë¢°ë„")
                if isinstance(rag_confidence, dict):
                    consistency = rag_confidence.get("consistency_score")
                    if consistency is not None:
                        confidences.append(float(consistency))
            
            return round(sum(confidences) / len(confidences), 2) if confidences else 0.0
        except Exception as e:
            print(f"âš ï¸ í‰ê·  ì‹ ë¢°ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0.0

    def _format_confidence_for_display(self, rag_confidence) -> str:
        """ì‹ ë¢°ë„ë¥¼ ë¡œê¹…ìš©ìœ¼ë¡œ í¬ë§·íŒ…"""
        if isinstance(rag_confidence, dict):
            consistency = rag_confidence.get("consistency_score", "N/A")
            peak = rag_confidence.get("peak_relevance_score", "N/A")
            return f"ì¼ê´€ì„±:{consistency}, ìµœê³ ì—°ê´€ë„:{peak}"
        return str(rag_confidence)